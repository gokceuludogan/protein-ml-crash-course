{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gokceuludogan/protein-ml-crash-course/blob/wip/Chapter_4_Secondary_Structure_Prediction_with_LSTM_model_%26_Pytorch_Lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Dw32R0bDUv-"
   },
   "source": [
    "## Overview\n",
    "\n",
    "In this chapter, we will predict **protein secondary structure**, which refers to the local folding of the protein's backbone into common motifs such as **alpha helices**, **beta sheets**, and **random coils**. This is a classic problem in bioinformatics that can be addressed using machine learning (ML) or deep learning (DL) techniques.\n",
    "\n",
    "We will:\n",
    "\n",
    "- Understand the protein secondary structure prediction task.\n",
    "- Encode protein sequences and their corresponding secondary structure labels.\n",
    "- Use both traditional ML and DL techniques to build predictive models.\n",
    "- Evaluate the performance of these models.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Protein Secondary Structure\n",
    "\n",
    "### Definitions:\n",
    "\n",
    "- **Primary structure**: The linear sequence of amino acids in the protein.\n",
    "- **Secondary structure**: Local folding patterns of the protein chain, mainly forming alpha helices (H), beta sheets (E), or random coils (C).\n",
    "- **Tertiary structure**: The overall 3D structure of the protein.\n",
    "\n",
    "### Common Classes in Secondary Structure Prediction:\n",
    "\n",
    "- **H**: Alpha-helix\n",
    "- **E**: Beta-sheet\n",
    "- **C**: Coil (random structure)\n",
    "\n",
    "### Dataset Example:\n",
    "\n",
    "We will work with a dataset where each protein sequence is accompanied by its secondary structure labels.\n",
    "\n",
    "| Sequence | Secondary Structure |\n",
    "| --- | --- |\n",
    "| MAGWELV | HCCCCCC |\n",
    "| GGQVNLL | CCECCEE |\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Data Preprocessing\n",
    "\n",
    "For this task, we will use the UniProt SwissProt database, which contains manually curated protein sequences. We will download the sequences in FASTA format and compute their secondary structures using DSSP (Define Secondary Structure of Proteins), a tool that assigns secondary structure elements (alpha-helix, beta-sheet, coil) based on 3D coordinates of the protein's structure.\n",
    "\n",
    "### Download UniProt SwissProt Database\n",
    "\n",
    "We will download the SwissProt database from the UniProt FTP server. This database contains high-quality, manually reviewed protein sequences.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M6IA8kOqK8Kr",
    "outputId": "ed8f5ad6-3436-4e1b-d90a-bbbad8527585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-04 16:05:50--  https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz\n",
      "Resolving ftp.uniprot.org (ftp.uniprot.org)... 128.175.240.195\n",
      "Connecting to ftp.uniprot.org (ftp.uniprot.org)|128.175.240.195|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 92678508 (88M) [application/x-gzip]\n",
      "Saving to: ‘uniprot_sprot.fasta.gz.1’\n",
      "\n",
      "uniprot_sprot.fasta  23%[===>                ]  20,62M  3,85MB/s    eta 20s    "
     ]
    }
   ],
   "source": [
    "!wget https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz\n",
    "!gunzip uniprot_sprot.fasta.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IbQqgZ0ZLVVc",
    "outputId": "5db92c06-ce4e-4829-9437-d32bab971d48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: biopython in ./ccourse/lib/python3.9/site-packages (1.84)\n",
      "Requirement already satisfied: numpy in ./ccourse/lib/python3.9/site-packages (from biopython) (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "R0IKZvsdLQKZ"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Set the file path for SwissProt\n",
    "swissprot_fasta = \"uniprot_sprot.fasta\"\n",
    "\n",
    "# Load SwissProt sequences and randomly sample 1000\n",
    "sequences = list(SeqIO.parse(swissprot_fasta, \"fasta\"))\n",
    "\n",
    "# Sample 1000 sequences\n",
    "sampled_sequences = random.sample(sequences, 100)\n",
    "\n",
    "# Extract UniProt IDs (they are in the FASTA header)\n",
    "uniprot_ids = [seq.id.split('|')[1] for seq in sampled_sequences]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bS7Wsz1bLpqJ"
   },
   "source": [
    "### Download AlphaFold structures using Bio.PDB.alphafold_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-1cFly7GLr34",
    "outputId": "4f8199b9-de5f-4c3a-f6ae-be4e3c9f3fa0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ozdeniz/Desktop/crashcourse/protein-ml-crash-course/ccourse/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded AlphaFold structure for Q55BU8\n",
      "Downloaded AlphaFold structure for Q5K2C4\n",
      "Downloaded AlphaFold structure for O78690\n",
      "Downloaded AlphaFold structure for Q6D827\n",
      "Downloaded AlphaFold structure for Q1E3Z7\n",
      "Downloaded AlphaFold structure for B7GJM6\n",
      "Downloaded AlphaFold structure for C0HKM2\n",
      "Downloaded AlphaFold structure for P03980\n",
      "Downloaded AlphaFold structure for Q58444\n",
      "Downloaded AlphaFold structure for A6WXE1\n",
      "Failed to download structure for P22677: 404\n",
      "Downloaded AlphaFold structure for V6CLJ5\n",
      "Downloaded AlphaFold structure for A5VQZ9\n",
      "Downloaded AlphaFold structure for A8G7M2\n",
      "Downloaded AlphaFold structure for Q71E89\n",
      "Downloaded AlphaFold structure for A9BUK3\n",
      "Downloaded AlphaFold structure for B3PI87\n",
      "Downloaded AlphaFold structure for B2TJ40\n",
      "Failed to download structure for P9WEN8: 404\n",
      "Downloaded AlphaFold structure for P85040\n",
      "Downloaded AlphaFold structure for Q1J5A9\n",
      "Downloaded AlphaFold structure for B6EIZ7\n",
      "Downloaded AlphaFold structure for Q1C0T8\n",
      "Downloaded AlphaFold structure for B5RQD7\n",
      "Downloaded AlphaFold structure for P54674\n",
      "Downloaded AlphaFold structure for B1YV68\n",
      "Failed to download structure for P20558: 404\n",
      "Downloaded AlphaFold structure for A2RE06\n",
      "Downloaded AlphaFold structure for B9E9J4\n",
      "Downloaded AlphaFold structure for A8GPD4\n",
      "Downloaded AlphaFold structure for A3DIM7\n",
      "Downloaded AlphaFold structure for P68107\n",
      "Downloaded AlphaFold structure for O76922\n",
      "Downloaded AlphaFold structure for P0CM48\n",
      "Downloaded AlphaFold structure for Q9NVV2\n",
      "Downloaded AlphaFold structure for Q88Y23\n",
      "Downloaded AlphaFold structure for Q5HL71\n",
      "Downloaded AlphaFold structure for Q17QT2\n",
      "Downloaded AlphaFold structure for Q8WUQ7\n",
      "Downloaded AlphaFold structure for B9E8X3\n",
      "Downloaded AlphaFold structure for Q02H55\n",
      "Downloaded AlphaFold structure for A1WF53\n",
      "Downloaded AlphaFold structure for Q7CKP5\n",
      "Downloaded AlphaFold structure for A4W0D2\n",
      "Downloaded AlphaFold structure for Q9HAE3\n",
      "Downloaded AlphaFold structure for O69717\n",
      "Downloaded AlphaFold structure for Q5E1N8\n",
      "Failed to download structure for P19151: 404\n",
      "Downloaded AlphaFold structure for Q2H5Z7\n",
      "Downloaded AlphaFold structure for P29628\n",
      "Downloaded AlphaFold structure for Q6FZQ6\n",
      "Downloaded AlphaFold structure for Q72CB6\n",
      "Downloaded AlphaFold structure for O94399\n",
      "Downloaded AlphaFold structure for P48798\n",
      "Downloaded AlphaFold structure for Q3TC72\n",
      "Downloaded AlphaFold structure for P02237\n",
      "Downloaded AlphaFold structure for O31893\n",
      "Downloaded AlphaFold structure for O13439\n",
      "Downloaded AlphaFold structure for A7WYW1\n",
      "Downloaded AlphaFold structure for Q9ULX5\n",
      "Downloaded AlphaFold structure for A4F6W7\n",
      "Downloaded AlphaFold structure for P16312\n",
      "Downloaded AlphaFold structure for Q9SNW5\n",
      "Downloaded AlphaFold structure for A5VJ89\n",
      "Downloaded AlphaFold structure for A4QK44\n",
      "Downloaded AlphaFold structure for A3QGY9\n",
      "Downloaded AlphaFold structure for B1LN20\n",
      "Downloaded AlphaFold structure for Q9R0P3\n",
      "Failed to download structure for Q64903: 404\n",
      "Downloaded AlphaFold structure for O16581\n",
      "Downloaded AlphaFold structure for P57031\n",
      "Downloaded AlphaFold structure for Q5YYH9\n",
      "Downloaded AlphaFold structure for A8LE22\n",
      "Downloaded AlphaFold structure for A4GDT9\n",
      "Downloaded AlphaFold structure for B3W9M6\n",
      "Downloaded AlphaFold structure for Q6BKI2\n",
      "Downloaded AlphaFold structure for P39466\n",
      "Downloaded AlphaFold structure for Q20F22\n",
      "Downloaded AlphaFold structure for Q8D1E4\n",
      "Downloaded AlphaFold structure for Q7ZU80\n",
      "Downloaded AlphaFold structure for Q8Y7G1\n",
      "Downloaded AlphaFold structure for A1V4K1\n",
      "Downloaded AlphaFold structure for Q84J50\n",
      "Downloaded AlphaFold structure for B7JJD5\n",
      "Downloaded AlphaFold structure for A3D2P0\n",
      "Downloaded AlphaFold structure for Q2NW13\n",
      "Downloaded AlphaFold structure for O84188\n",
      "Downloaded AlphaFold structure for P0DKC1\n",
      "Downloaded AlphaFold structure for A7MQ63\n",
      "Downloaded AlphaFold structure for B1JK18\n",
      "Downloaded AlphaFold structure for Q4KLI1\n",
      "Downloaded AlphaFold structure for O44440\n",
      "Failed to download structure for P0CF95: 404\n",
      "Downloaded AlphaFold structure for A9AVV0\n",
      "Downloaded AlphaFold structure for Q5LP83\n",
      "Downloaded AlphaFold structure for Q2YNM6\n",
      "Downloaded AlphaFold structure for Q8EFW4\n",
      "Downloaded AlphaFold structure for Q5PIK4\n",
      "Downloaded AlphaFold structure for P63805\n",
      "Downloaded AlphaFold structure for Q6ADU9\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "# Directory to store AlphaFold structures\n",
    "output_dir = \"alphafold_structures\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to download AlphaFold structure from API\n",
    "def download_alphafold_structure(uniprot_id, output_dir):\n",
    "    url = f\"https://alphafold.com/api/prediction/{uniprot_id}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        response = requests.get(response.json()[0]['pdbUrl'])\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to download structure for {uniprot_id}: {response.status_code}\")\n",
    "            return None\n",
    "        output_file = os.path.join(output_dir, f\"{uniprot_id}.pdb\")\n",
    "        with open(output_file, \"w\") as f:\n",
    "            f.write(response.text)\n",
    "        print(f\"Downloaded AlphaFold structure for {uniprot_id}\")\n",
    "        return output_file\n",
    "    else:\n",
    "        print(f\"Failed to download structure for {uniprot_id}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Download AlphaFold structures for sampled UniProt IDs\n",
    "pdb_files = []\n",
    "for uniprot_id in uniprot_ids:\n",
    "    pdb_file = download_alphafold_structure(uniprot_id, output_dir)\n",
    "    if pdb_file:\n",
    "        pdb_files.append(pdb_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rj743kgTg-Sj",
    "outputId": "09e635dc-c6b2-4ce7-8377-f07273f5048b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: apt-get\n"
     ]
    }
   ],
   "source": [
    "!apt-get install dssp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_1clq9-NWiP"
   },
   "source": [
    "### Compute Secondary Structures using DSSP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DCi3WlhNO8O",
    "outputId": "6b386872-e8e5-4a32-fc7b-9db5e801f175"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secondary structure computation completed and saved.\n"
     ]
    }
   ],
   "source": [
    "from Bio.PDB import PDBParser\n",
    "from Bio.PDB import DSSP\n",
    "\n",
    "parser = PDBParser(QUIET=True)\n",
    "\n",
    "# Dictionary to store UniProt ID and secondary structure assignment\n",
    "secondary_structures = {}\n",
    "\n",
    "for pdb_file in pdb_files:\n",
    "    try:\n",
    "        # Parse the AlphaFold structure\n",
    "        structure = parser.get_structure(\"model\", pdb_file)\n",
    "        model = structure[0]\n",
    "\n",
    "        # Apply DSSP to the AlphaFold model\n",
    "        dssp = DSSP(model, pdb_file)\n",
    "\n",
    "        # Extract secondary structure assignment\n",
    "        sec_struct = [item[2] for item in dssp]\n",
    "        uniprot_id = os.path.basename(pdb_file).split('.')[0]\n",
    "        secondary_structures[uniprot_id] = sec_struct\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Error in computing secondary structure for ', pdb_file)\n",
    "# Save secondary structures to file\n",
    "import json\n",
    "with open(\"secondary_structures.json\", \"w\") as f:\n",
    "    json.dump(secondary_structures, f)\n",
    "\n",
    "print(\"Secondary structure computation completed and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNnT5wB4LGS2"
   },
   "source": [
    "### Encoding Sequences and Structures\n",
    "\n",
    "Similar to Chapter 3, we will **one-hot encode** the amino acid sequences. The secondary structure labels (H, E, C) will also be encoded, but instead of one-hot encoding, we can map each label to a unique integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4K3NXXCfDJdn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Define amino acids and secondary structure mappings\n",
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "aa_to_int = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "structure_to_int = {'H': 0, 'E': 1, 'T': 2, 'B': 3, 'S': 4, 'G': 5, 'P': 6, 'I': 7, '-': 8}\n",
    "\n",
    "# Function to read sequences from a FASTA file\n",
    "def read_fasta_to_dict(fasta_file):\n",
    "    seq_dict = {}\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        seq_dict[record.id.split('|')[1]] = str(record.seq)\n",
    "    return seq_dict\n",
    "\n",
    "# Function to encode sequences\n",
    "def one_hot_encode_sequence(sequence):\n",
    "    one_hot = np.zeros((len(sequence), len(amino_acids)))\n",
    "    for i, aa in enumerate(sequence):\n",
    "        if aa in aa_to_int:\n",
    "            one_hot[i, aa_to_int[aa]] = 1\n",
    "    return one_hot\n",
    "\n",
    "# Function to encode secondary structure\n",
    "def encode_structure(structure):\n",
    "    one_hot = np.zeros((len(structure), len(structure_to_int)))\n",
    "    for i, ss in enumerate(structure):\n",
    "        if ss in structure_to_int:\n",
    "            one_hot[i, structure_to_int[ss]] = 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "# Function to pad or truncate sequences\n",
    "def pad_or_truncate_sequence(sequence, target_length):\n",
    "    if len(sequence) > target_length:\n",
    "        return sequence[:target_length]\n",
    "    elif len(sequence) < target_length:\n",
    "        padding_length = target_length - len(sequence)\n",
    "        return np.pad(sequence, ((0, padding_length), (0, 0)), 'constant')\n",
    "    else:\n",
    "        return sequence\n",
    "\n",
    "\n",
    "# Example usage\n",
    "fasta_file = \"uniprot_sprot.fasta\"  # Path to your FASTA file\n",
    "sequence_dict = read_fasta_to_dict(fasta_file)\n",
    "\n",
    "# Initialize lists to store the processed data\n",
    "X_windows = []\n",
    "encoded_structure = []\n",
    "\n",
    "# Define a fixed window size\n",
    "window_size = 100  # You can choose the appropriate size based on your data\n",
    "\n",
    "for uniprot_id, ss in secondary_structures.items():\n",
    "\n",
    "    if uniprot_id in sequence_dict:\n",
    "        sequence = sequence_dict[uniprot_id]\n",
    "\n",
    "        # One-hot encode the amino acid sequence\n",
    "        encoded_sequence = one_hot_encode_sequence(sequence)\n",
    "\n",
    "        # Pad or truncate to ensure fixed length\n",
    "        padded_sequence = pad_or_truncate_sequence(encoded_sequence, window_size)\n",
    "\n",
    "        X_windows.append(padded_sequence)\n",
    "        encoded_structure.append(pad_or_truncate_sequence(encode_structure(ss), window_size))\n",
    "\n",
    "\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_windows = np.array(X_windows)  # Shape: (num_samples, window_size, num_features)\n",
    "encoded_structure = np.array(encoded_structure)  # Shape: (num_samples, window_size)\n",
    "\n",
    "# Flatten encoded_structure if required (you might want to change this)\n",
    "# encoded_structure = encoded_structure.flatten()  # Adjust based on your needs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3xGnMM-hRSZD"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_windows, encoded_structure, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoaders for training and validation sets\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37VjDQRNDpjY"
   },
   "source": [
    "## Deep Learning for Secondary Structure Prediction\n",
    "\n",
    "Deep learning models, such as **Recurrent Neural Networks (RNNs)** or **Convolutional Neural Networks (CNNs)**, can capture sequential patterns more effectively for this type of task.\n",
    "\n",
    "### LSTM (Long Short-Term Memory) Model\n",
    "\n",
    "LSTMs are a type of RNN that can capture long-range dependencies, making them a powerful choice for sequence-based tasks like secondary structure prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3FsKSIMGIDY",
    "outputId": "9e400576-0f82-4265-a54c-54c879058c7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting torch>=2.1.0 (from pytorch-lightning)\n",
      "  Downloading torch-2.4.1-cp39-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Collecting tqdm>=4.57.0 (from pytorch-lightning)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: PyYAML>=5.4 in ./ccourse/lib/python3.9/site-packages (from pytorch-lightning) (6.0.2)\n",
      "Collecting fsspec>=2022.5.0 (from fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
      "  Downloading torchmetrics-1.4.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./ccourse/lib/python3.9/site-packages (from pytorch-lightning) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in ./ccourse/lib/python3.9/site-packages (from pytorch-lightning) (4.12.2)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
      "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading aiohttp-3.10.8-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: setuptools in ./ccourse/lib/python3.9/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.1.0)\n",
      "Collecting filelock (from torch>=2.1.0->pytorch-lightning)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting sympy (from torch>=2.1.0->pytorch-lightning)\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=2.1.0->pytorch-lightning)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in ./ccourse/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning) (3.1.4)\n",
      "Requirement already satisfied: numpy>1.20.0 in ./ccourse/lib/python3.9/site-packages (from torchmetrics>=0.7.0->pytorch-lightning) (2.0.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./ccourse/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading multidict-6.1.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading yarl-1.13.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (50 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./ccourse/lib/python3.9/site-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (2.1.5)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=2.1.0->pytorch-lightning)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: idna>=2.0 in ./ccourse/lib/python3.9/site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
      "Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
      "Downloading torch-2.4.1-cp39-none-macosx_11_0_arm64.whl (62.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.4.2-py3-none-any.whl (869 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.2/869.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Downloading aiohttp-3.10.8-cp39-cp39-macosx_11_0_arm64.whl (391 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp39-cp39-macosx_11_0_arm64.whl (53 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp39-cp39-macosx_11_0_arm64.whl (29 kB)\n",
      "Downloading yarl-1.13.1-cp39-cp39-macosx_11_0_arm64.whl (115 kB)\n",
      "Installing collected packages: mpmath, tqdm, sympy, networkx, multidict, lightning-utilities, fsspec, frozenlist, filelock, async-timeout, aiohappyeyeballs, yarl, torch, aiosignal, torchmetrics, aiohttp, pytorch-lightning\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.10.8 aiosignal-1.3.1 async-timeout-4.0.3 filelock-3.16.1 frozenlist-1.4.1 fsspec-2024.9.0 lightning-utilities-0.11.7 mpmath-1.3.0 multidict-6.1.0 networkx-3.2.1 pytorch-lightning-2.4.0 sympy-1.13.3 torch-2.4.1 torchmetrics-1.4.2 tqdm-4.66.5 yarl-1.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "HYqDyCWcIv7r"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type               | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | lstm     | LSTM               | 22.0 K | train\n",
      "1 | fc       | Linear             | 585    | train\n",
      "2 | loss_fn  | CrossEntropyLoss   | 0      | train\n",
      "3 | accuracy | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------\n",
      "22.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "22.6 K    Total params\n",
      "0.090     Total estimated model params size (MB)\n",
      "4         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeae019811974ac3befac4fa86e91d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d406e5b48bf34b93a40cb63e1dffb12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330ea86fa7cc4ee9a32a2dc072a59282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d05cd8fd0e45e7be15032457d08d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7414ba8ca2140e68fa7d720fcbc8f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6df215cbe144acc89d03e9478f3cb5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65e6903de1f4550bb1ad6250ce9d70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c929da42c00c4d6b9bf8ed65dddf1a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b3f74a506147a7b2687cae52140c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343b2557e7684dae9db9a6792c7b0f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260572edbe1e4fbb931516a1d98fd006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af040f79cdcf4bc88a50cb96cc836e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487b99f0cb824480b76c70f1c18e822e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         val_acc            0.37684211134910583\n",
      "        val_loss            1.6694083213806152\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 1.6694083213806152, 'val_acc': 0.37684211134910583}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# Define the PyTorch Lightning module\n",
    "class LSTMModel(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=1e-3):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.accuracy = Accuracy(task=\"multiclass\", num_classes=output_size)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out)  # Apply fully connected layer to each time step\n",
    "        return out # Shape: (batch_size, window_size, output_size)\n",
    "\n",
    "    # Training step (one batch)\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        # Reshape outputs and labels for loss calculation (flatten time steps and batch size)\n",
    "        outputs = outputs.view(-1, outputs.shape[-1])  # (batch_size * window_size, output_size)\n",
    "        labels = labels.view(-1, labels.shape[-1])  # (batch_size * window_size)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        acc = self.accuracy(torch.argmax(outputs, dim=1), torch.argmax(labels, dim=1))\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    # Validation step (one batch)\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        outputs = outputs.view(-1, outputs.shape[-1])\n",
    "        labels = labels.view(-1, labels.shape[-1])\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        acc = self.accuracy(torch.argmax(outputs, dim=1), torch.argmax(labels, dim=1))\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "    # Predict method to return predicted labels\n",
    "    def predict(self, x):\n",
    "        self.eval()  # Set model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            outputs = self(x)  # Forward pass\n",
    "            predicted_labels = torch.argmax(outputs, dim=1)  # Get predicted class (max value along class dimension)\n",
    "        return predicted_labels\n",
    "\n",
    "    # Optimizer setup\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "# Define the model\n",
    "input_size = X_windows.shape[2]  # Number of features (e.g., amino acids)\n",
    "hidden_size = 64  # Number of LSTM units\n",
    "output_size = 9   # Number of classes\n",
    "\n",
    "# Create an instance of the model\n",
    "model = LSTMModel(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
    "\n",
    "# Initialize the PyTorch Lightning Trainer\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"auto\", devices=\"auto\")  # Automatically uses GPU if available\n",
    "\n",
    "# Train the model using the Trainer (like model.fit)\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "# Optionally, evaluate the model on a test set (similar to model.evaluate)\n",
    "trainer.validate(model, dataloaders=val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmRuhohTDtYT"
   },
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "We can evaluate the performance of our models using metrics such as **accuracy**, **precision**, and **recall**. In secondary structure prediction, it's important to measure the performance for each class (H, E, C) individually as well as the overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "549Xfc7DDvjx"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Get predictions for the validation data\n",
    "predictions = model.predict(X_val_tensor)\n",
    "\n",
    "# LSTM Evaluation (for demonstration, evaluating on training data)\n",
    "lstm_pred = model.predict(X_val_tensor).cpu().numpy()\n",
    "\n",
    "# Flatten both predictions and true labels to compare them element-wise\n",
    "lstm_pred_flat = lstm_pred.view(-1).cpu().numpy()  # Flatten the predicted labels and move to CPU\n",
    "y_val_flat = y_val_tensor.view(-1).cpu().numpy()   # Flatten the true labels and move to CPU\n",
    "\n",
    "# Generate the classification report\n",
    "target_names = ['Helix (H)', 'Sheet (E)', 'Coil (C)', 'Turn (T)', 'Bend (B)', 'Bridge (G)', 'Polyproline (P)', 'I-helix (I)', 'Other (-)']\n",
    "lstm_report = classification_report(y_val_flat, lstm_pred_flat, target_names=target_names)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"LSTM Classification Report:\\n\", lstm_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3v-NDlQGDybB"
   },
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "In this chapter, we built machine learning and deep learning models to predict protein secondary structure from amino acid sequences. We explored the use of traditional classifiers like Random Forests and advanced deep learning architectures like LSTMs. While traditional methods perform well for small datasets, deep learning models can capture long-range dependencies and improve performance when dealing with larger datasets."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ccourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
