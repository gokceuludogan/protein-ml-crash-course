{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gokceuludogan/protein-ml-crash-course/blob/wip/Chapter_4_Secondary_Structure_Prediction_with_LSTM_model_%26_Pytorch_Lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "In this chapter, we will predict **protein secondary structure**, which refers to the local folding of the protein's backbone into common motifs such as **alpha helices**, **beta sheets**, and **random coils**. This is a classic problem in bioinformatics that can be addressed using machine learning (ML) or deep learning (DL) techniques.\n",
        "\n",
        "We will:\n",
        "\n",
        "- Understand the protein secondary structure prediction task.\n",
        "- Encode protein sequences and their corresponding secondary structure labels.\n",
        "- Use both traditional ML and DL techniques to build predictive models.\n",
        "- Evaluate the performance of these models.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Protein Secondary Structure\n",
        "\n",
        "### Definitions:\n",
        "\n",
        "- **Primary structure**: The linear sequence of amino acids in the protein.\n",
        "- **Secondary structure**: Local folding patterns of the protein chain, mainly forming alpha helices (H), beta sheets (E), or random coils (C).\n",
        "- **Tertiary structure**: The overall 3D structure of the protein.\n",
        "\n",
        "### Common Classes in Secondary Structure Prediction:\n",
        "\n",
        "- **H**: Alpha-helix\n",
        "- **E**: Beta-sheet\n",
        "- **C**: Coil (random structure)\n",
        "\n",
        "### Dataset Example:\n",
        "\n",
        "We will work with a dataset where each protein sequence is accompanied by its secondary structure labels.\n",
        "\n",
        "| Sequence | Secondary Structure |\n",
        "| --- | --- |\n",
        "| MAGWELV | HCCCCCC |\n",
        "| GGQVNLL | CCECCEE |\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Data Preprocessing\n",
        "\n",
        "For this task, we will use the UniProt SwissProt database, which contains manually curated protein sequences. We will download the sequences in FASTA format and compute their secondary structures using DSSP (Define Secondary Structure of Proteins), a tool that assigns secondary structure elements (alpha-helix, beta-sheet, coil) based on 3D coordinates of the protein's structure.\n",
        "\n",
        "### Download UniProt SwissProt Database\n",
        "\n",
        "We will download the SwissProt database from the UniProt FTP server. This database contains high-quality, manually reviewed protein sequences.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8Dw32R0bDUv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz\n",
        "!gunzip uniprot_sprot.fasta.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6IA8kOqK8Kr",
        "outputId": "b6432734-7efa-4e66-b0d9-bf11ac450000"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-02 12:59:24--  https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz\n",
            "Resolving ftp.uniprot.org (ftp.uniprot.org)... 128.175.240.195\n",
            "Connecting to ftp.uniprot.org (ftp.uniprot.org)|128.175.240.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 92500409 (88M) [application/x-gzip]\n",
            "Saving to: ‘uniprot_sprot.fasta.gz’\n",
            "\n",
            "uniprot_sprot.fasta 100%[===================>]  88.21M  84.2MB/s    in 1.0s    \n",
            "\n",
            "2024-10-02 12:59:26 (84.2 MB/s) - ‘uniprot_sprot.fasta.gz’ saved [92500409/92500409]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbQqgZ0ZLVVc",
        "outputId": "2200d54c-6ab1-4ba5-c4ef-ba0796b882a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.26.4)\n",
            "Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: biopython\n",
            "Successfully installed biopython-1.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from Bio import SeqIO\n",
        "\n",
        "# Set the file path for SwissProt\n",
        "swissprot_fasta = \"uniprot_sprot.fasta\"\n",
        "\n",
        "# Load SwissProt sequences and randomly sample 1000\n",
        "sequences = list(SeqIO.parse(swissprot_fasta, \"fasta\"))\n",
        "\n",
        "# Sample 1000 sequences\n",
        "sampled_sequences = random.sample(sequences, 100)\n",
        "\n",
        "# Extract UniProt IDs (they are in the FASTA header)\n",
        "uniprot_ids = [seq.id.split('|')[1] for seq in sampled_sequences]\n"
      ],
      "metadata": {
        "id": "R0IKZvsdLQKZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download AlphaFold structures using Bio.PDB.alphafold_db\n"
      ],
      "metadata": {
        "id": "bS7Wsz1bLpqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "# Directory to store AlphaFold structures\n",
        "output_dir = \"alphafold_structures\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Function to download AlphaFold structure from API\n",
        "def download_alphafold_structure(uniprot_id, output_dir):\n",
        "    url = f\"https://alphafold.com/api/prediction/{uniprot_id}\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        response = requests.get(response.json()[0]['pdbUrl'])\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Failed to download structure for {uniprot_id}: {response.status_code}\")\n",
        "            return None\n",
        "        output_file = os.path.join(output_dir, f\"{uniprot_id}.pdb\")\n",
        "        with open(output_file, \"w\") as f:\n",
        "            f.write(response.text)\n",
        "        print(f\"Downloaded AlphaFold structure for {uniprot_id}\")\n",
        "        return output_file\n",
        "    else:\n",
        "        print(f\"Failed to download structure for {uniprot_id}: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "# Download AlphaFold structures for sampled UniProt IDs\n",
        "pdb_files = []\n",
        "for uniprot_id in uniprot_ids:\n",
        "    pdb_file = download_alphafold_structure(uniprot_id, output_dir)\n",
        "    if pdb_file:\n",
        "        pdb_files.append(pdb_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1cFly7GLr34",
        "outputId": "2357297d-815e-414b-f28a-c5187167f070"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded AlphaFold structure for Q4WR83\n",
            "Downloaded AlphaFold structure for Q44241\n",
            "Downloaded AlphaFold structure for Q9NXD2\n",
            "Downloaded AlphaFold structure for C1D558\n",
            "Downloaded AlphaFold structure for Q7L576\n",
            "Downloaded AlphaFold structure for A4QJZ8\n",
            "Downloaded AlphaFold structure for Q5M579\n",
            "Downloaded AlphaFold structure for B2VIR2\n",
            "Downloaded AlphaFold structure for B7L4J2\n",
            "Failed to download structure for Q20P38: 404\n",
            "Downloaded AlphaFold structure for A1RP91\n",
            "Downloaded AlphaFold structure for A0LXJ4\n",
            "Downloaded AlphaFold structure for Q06179\n",
            "Downloaded AlphaFold structure for A8AYN4\n",
            "Downloaded AlphaFold structure for A9GVS8\n",
            "Downloaded AlphaFold structure for B1W4V1\n",
            "Downloaded AlphaFold structure for P85883\n",
            "Downloaded AlphaFold structure for P9WLP3\n",
            "Downloaded AlphaFold structure for P03052\n",
            "Downloaded AlphaFold structure for Q90495\n",
            "Downloaded AlphaFold structure for A1UZX5\n",
            "Downloaded AlphaFold structure for Q29RJ9\n",
            "Downloaded AlphaFold structure for A1W2Q2\n",
            "Downloaded AlphaFold structure for Q758Q9\n",
            "Downloaded AlphaFold structure for A6WLV9\n",
            "Downloaded AlphaFold structure for B7N0K2\n",
            "Downloaded AlphaFold structure for O74907\n",
            "Downloaded AlphaFold structure for A3QCE0\n",
            "Downloaded AlphaFold structure for B8ZSY2\n",
            "Downloaded AlphaFold structure for P33711\n",
            "Downloaded AlphaFold structure for Q06091\n",
            "Downloaded AlphaFold structure for Q4UNF2\n",
            "Downloaded AlphaFold structure for Q5ZYH6\n",
            "Downloaded AlphaFold structure for O69731\n",
            "Downloaded AlphaFold structure for A5F382\n",
            "Downloaded AlphaFold structure for Q2TA06\n",
            "Downloaded AlphaFold structure for Q6PDG5\n",
            "Downloaded AlphaFold structure for Q2W5T9\n",
            "Failed to download structure for P04889: 404\n",
            "Downloaded AlphaFold structure for Q8TCE6\n",
            "Downloaded AlphaFold structure for Q2UDK7\n",
            "Downloaded AlphaFold structure for B1YG95\n",
            "Downloaded AlphaFold structure for A7X2P6\n",
            "Downloaded AlphaFold structure for Q2P1M3\n",
            "Downloaded AlphaFold structure for A0LRC6\n",
            "Downloaded AlphaFold structure for Q2R837\n",
            "Downloaded AlphaFold structure for Q12756\n",
            "Downloaded AlphaFold structure for Q96SA4\n",
            "Downloaded AlphaFold structure for Q74GV1\n",
            "Downloaded AlphaFold structure for P10054\n",
            "Downloaded AlphaFold structure for Q9JHB5\n",
            "Downloaded AlphaFold structure for Q2YLW7\n",
            "Downloaded AlphaFold structure for Q9Z3R3\n",
            "Downloaded AlphaFold structure for Q1G904\n",
            "Downloaded AlphaFold structure for O33658\n",
            "Downloaded AlphaFold structure for B5RGA3\n",
            "Downloaded AlphaFold structure for Q89T55\n",
            "Downloaded AlphaFold structure for P0CU73\n",
            "Downloaded AlphaFold structure for A1VIP6\n",
            "Downloaded AlphaFold structure for P29446\n",
            "Downloaded AlphaFold structure for Q7W7P8\n",
            "Downloaded AlphaFold structure for Q0VN66\n",
            "Downloaded AlphaFold structure for P9WHW4\n",
            "Downloaded AlphaFold structure for Q58020\n",
            "Downloaded AlphaFold structure for O05231\n",
            "Downloaded AlphaFold structure for A9R6N8\n",
            "Downloaded AlphaFold structure for Q05588\n",
            "Downloaded AlphaFold structure for A7A1I2\n",
            "Downloaded AlphaFold structure for A9MV69\n",
            "Downloaded AlphaFold structure for B4U2B4\n",
            "Downloaded AlphaFold structure for A4ITJ1\n",
            "Downloaded AlphaFold structure for B4T4G5\n",
            "Downloaded AlphaFold structure for S0E2Y2\n",
            "Failed to download structure for Q6SW66: 404\n",
            "Downloaded AlphaFold structure for B6J4H6\n",
            "Downloaded AlphaFold structure for P41119\n",
            "Downloaded AlphaFold structure for Q9USK3\n",
            "Downloaded AlphaFold structure for P49586\n",
            "Downloaded AlphaFold structure for Q9C660\n",
            "Downloaded AlphaFold structure for C7GWA5\n",
            "Downloaded AlphaFold structure for Q96LW2\n",
            "Downloaded AlphaFold structure for A5TZF5\n",
            "Downloaded AlphaFold structure for A8H5P7\n",
            "Downloaded AlphaFold structure for Q8F498\n",
            "Downloaded AlphaFold structure for A8G084\n",
            "Downloaded AlphaFold structure for A9N238\n",
            "Downloaded AlphaFold structure for Q2IL38\n",
            "Downloaded AlphaFold structure for P95225\n",
            "Downloaded AlphaFold structure for Q7VJ35\n",
            "Downloaded AlphaFold structure for B7NR43\n",
            "Downloaded AlphaFold structure for B7NH70\n",
            "Downloaded AlphaFold structure for Q9CN56\n",
            "Downloaded AlphaFold structure for A6W5S6\n",
            "Downloaded AlphaFold structure for A1WVB5\n",
            "Downloaded AlphaFold structure for Q2T0L3\n",
            "Downloaded AlphaFold structure for Q9D3J8\n",
            "Downloaded AlphaFold structure for P29552\n",
            "Downloaded AlphaFold structure for A3NTA9\n",
            "Downloaded AlphaFold structure for B1XWB1\n",
            "Downloaded AlphaFold structure for C1EW38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install dssp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj743kgTg-Sj",
        "outputId": "88f61796-b268-4406-c923-64411f414e9d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libcifpp-data libcifpp2\n",
            "The following NEW packages will be installed:\n",
            "  dssp libcifpp-data libcifpp2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 1,967 kB of archives.\n",
            "After this operation, 15.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcifpp-data all 2.0.5-1build1 [437 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcifpp2 amd64 2.0.5-1build1 [1,019 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dssp amd64 4.0.4-1 [511 kB]\n",
            "Fetched 1,967 kB in 1s (1,618 kB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package libcifpp-data.\n",
            "(Reading database ... 123614 files and directories currently installed.)\n",
            "Preparing to unpack .../libcifpp-data_2.0.5-1build1_all.deb ...\n",
            "Unpacking libcifpp-data (2.0.5-1build1) ...\n",
            "Selecting previously unselected package libcifpp2:amd64.\n",
            "Preparing to unpack .../libcifpp2_2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libcifpp2:amd64 (2.0.5-1build1) ...\n",
            "Selecting previously unselected package dssp.\n",
            "Preparing to unpack .../dssp_4.0.4-1_amd64.deb ...\n",
            "Unpacking dssp (4.0.4-1) ...\n",
            "Setting up libcifpp-data (2.0.5-1build1) ...\n",
            "Setting up libcifpp2:amd64 (2.0.5-1build1) ...\n",
            "Setting up dssp (4.0.4-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute Secondary Structures using DSSP."
      ],
      "metadata": {
        "id": "w_1clq9-NWiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio.PDB import PDBParser\n",
        "from Bio.PDB import DSSP\n",
        "\n",
        "parser = PDBParser(QUIET=True)\n",
        "\n",
        "# Dictionary to store UniProt ID and secondary structure assignment\n",
        "secondary_structures = {}\n",
        "\n",
        "for pdb_file in pdb_files:\n",
        "    try:\n",
        "        # Parse the AlphaFold structure\n",
        "        structure = parser.get_structure(\"model\", pdb_file)\n",
        "        model = structure[0]\n",
        "\n",
        "        # Apply DSSP to the AlphaFold model\n",
        "        dssp = DSSP(model, pdb_file)\n",
        "\n",
        "        # Extract secondary structure assignment\n",
        "        sec_struct = [item[2] for item in dssp]\n",
        "        uniprot_id = os.path.basename(pdb_file).split('.')[0]\n",
        "        secondary_structures[uniprot_id] = sec_struct\n",
        "\n",
        "    except Exception as e:\n",
        "        print('Error in computing secondary structure for ', pdb_file)\n",
        "# Save secondary structures to file\n",
        "import json\n",
        "with open(\"secondary_structures.json\", \"w\") as f:\n",
        "    json.dump(secondary_structures, f)\n",
        "\n",
        "print(\"Secondary structure computation completed and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DCi3WlhNO8O",
        "outputId": "efbcc8ac-5564-4fe8-eed2-2c0eeeb24506"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Secondary structure computation completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding Sequences and Structures\n",
        "\n",
        "Similar to Chapter 3, we will **one-hot encode** the amino acid sequences. The secondary structure labels (H, E, C) will also be encoded, but instead of one-hot encoding, we can map each label to a unique integer."
      ],
      "metadata": {
        "id": "sNnT5wB4LGS2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4K3NXXCfDJdn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from Bio import SeqIO\n",
        "\n",
        "# Define amino acids and secondary structure mappings\n",
        "amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "aa_to_int = {aa: i for i, aa in enumerate(amino_acids)}\n",
        "structure_to_int = {'H': 0, 'E': 1, 'T': 2, 'B': 3, 'S': 4, 'G': 5, 'P': 6, 'I': 7, '-': 8}\n",
        "\n",
        "# Function to read sequences from a FASTA file\n",
        "def read_fasta_to_dict(fasta_file):\n",
        "    seq_dict = {}\n",
        "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "        seq_dict[record.id.split('|')[1]] = str(record.seq)\n",
        "    return seq_dict\n",
        "\n",
        "# Function to encode sequences\n",
        "def one_hot_encode_sequence(sequence):\n",
        "    one_hot = np.zeros((len(sequence), len(amino_acids)))\n",
        "    for i, aa in enumerate(sequence):\n",
        "        if aa in aa_to_int:\n",
        "            one_hot[i, aa_to_int[aa]] = 1\n",
        "    return one_hot\n",
        "\n",
        "# Function to encode secondary structure\n",
        "def encode_structure(structure):\n",
        "    one_hot = np.zeros((len(structure), len(structure_to_int)))\n",
        "    for i, ss in enumerate(structure):\n",
        "        if ss in structure_to_int:\n",
        "            one_hot[i, structure_to_int[ss]] = 1\n",
        "    return one_hot\n",
        "\n",
        "\n",
        "# Function to pad or truncate sequences\n",
        "def pad_or_truncate_sequence(sequence, target_length):\n",
        "    if len(sequence) > target_length:\n",
        "        return sequence[:target_length]\n",
        "    elif len(sequence) < target_length:\n",
        "        padding_length = target_length - len(sequence)\n",
        "        return np.pad(sequence, ((0, padding_length), (0, 0)), 'constant')\n",
        "    else:\n",
        "        return sequence\n",
        "\n",
        "\n",
        "# Example usage\n",
        "fasta_file = \"uniprot_sprot.fasta\"  # Path to your FASTA file\n",
        "sequence_dict = read_fasta_to_dict(fasta_file)\n",
        "\n",
        "# Initialize lists to store the processed data\n",
        "X_windows = []\n",
        "encoded_structure = []\n",
        "\n",
        "# Define a fixed window size\n",
        "window_size = 100  # You can choose the appropriate size based on your data\n",
        "\n",
        "for uniprot_id, ss in secondary_structures.items():\n",
        "\n",
        "    if uniprot_id in sequence_dict:\n",
        "        sequence = sequence_dict[uniprot_id]\n",
        "\n",
        "        # One-hot encode the amino acid sequence\n",
        "        encoded_sequence = one_hot_encode_sequence(sequence)\n",
        "\n",
        "        # Pad or truncate to ensure fixed length\n",
        "        padded_sequence = pad_or_truncate_sequence(encoded_sequence, window_size)\n",
        "\n",
        "        X_windows.append(padded_sequence)\n",
        "        encoded_structure.append(pad_or_truncate_sequence(encode_structure(ss), window_size))\n",
        "\n",
        "\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_windows = np.array(X_windows)  # Shape: (num_samples, window_size, num_features)\n",
        "encoded_structure = np.array(encoded_structure)  # Shape: (num_samples, window_size)\n",
        "\n",
        "# Flatten encoded_structure if required (you might want to change this)\n",
        "# encoded_structure = encoded_structure.flatten()  # Adjust based on your needs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_windows, encoded_structure, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "# Create DataLoaders for training and validation sets\n",
        "batch_size = 32\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "3xGnMM-hRSZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning for Secondary Structure Prediction\n",
        "\n",
        "Deep learning models, such as **Recurrent Neural Networks (RNNs)** or **Convolutional Neural Networks (CNNs)**, can capture sequential patterns more effectively for this type of task.\n",
        "\n",
        "### LSTM (Long Short-Term Memory) Model\n",
        "\n",
        "LSTMs are a type of RNN that can capture long-range dependencies, making them a powerful choice for sequence-based tasks like secondary structure prediction."
      ],
      "metadata": {
        "id": "37VjDQRNDpjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "d3FsKSIMGIDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pytorch_lightning as pl\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "# Define the PyTorch Lightning module\n",
        "class LSTMModel(pl.LightningModule):\n",
        "    def __init__(self, input_size, hidden_size, output_size, learning_rate=1e-3):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "        self.accuracy = Accuracy(task=\"multiclass\", num_classes=output_size)\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        out = self.fc(lstm_out)  # Apply fully connected layer to each time step\n",
        "        return out # Shape: (batch_size, window_size, output_size)\n",
        "\n",
        "    # Training step (one batch)\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        inputs, labels = batch\n",
        "        outputs = self(inputs)\n",
        "        # Reshape outputs and labels for loss calculation (flatten time steps and batch size)\n",
        "        outputs = outputs.view(-1, outputs.shape[-1])  # (batch_size * window_size, output_size)\n",
        "        labels = labels.view(-1)  # (batch_size * window_size)\n",
        "        loss = self.loss_fn(outputs, labels)\n",
        "        acc = self.accuracy(outputs, labels)\n",
        "        self.log('train_loss', loss)\n",
        "        self.log('train_acc', acc, prog_bar=True)\n",
        "\n",
        "\n",
        "    # Validation step (one batch)\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        inputs, labels = batch\n",
        "        outputs = self(inputs)\n",
        "        outputs = outputs.view(-1, outputs.shape[-1])\n",
        "        labels = labels.view(-1)\n",
        "        loss = self.loss_fn(outputs, labels)\n",
        "        acc = self.accuracy(outputs, labels)\n",
        "        self.log('val_loss', loss)\n",
        "        self.log('val_acc', acc, prog_bar=True)\n",
        "\n",
        "    # Predict method to return predicted labels\n",
        "    def predict(self, x):\n",
        "        self.eval()  # Set model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            outputs = self(x)  # Forward pass\n",
        "            predicted_labels = torch.argmax(outputs, dim=1)  # Get predicted class (max value along class dimension)\n",
        "        return predicted_labels\n",
        "\n",
        "    # Optimizer setup\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "# Define the model\n",
        "input_size = X_windows.shape[2]  # Number of features (e.g., amino acids)\n",
        "hidden_size = 64  # Number of LSTM units\n",
        "output_size = 9   # Number of classes\n",
        "\n",
        "# Create an instance of the model\n",
        "model = LSTMModel(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
        "\n",
        "# Initialize the PyTorch Lightning Trainer\n",
        "trainer = pl.Trainer(max_epochs=10, accelerator=\"auto\", devices=\"auto\")  # Automatically uses GPU if available\n",
        "\n",
        "# Train the model using the Trainer (like model.fit)\n",
        "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
        "\n",
        "# Optionally, evaluate the model on a test set (similar to model.evaluate)\n",
        "trainer.validate(model, dataloaders=val_loader)\n"
      ],
      "metadata": {
        "id": "HYqDyCWcIv7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Model Evaluation\n",
        "\n",
        "We can evaluate the performance of our models using metrics such as **accuracy**, **precision**, and **recall**. In secondary structure prediction, it's important to measure the performance for each class (H, E, C) individually as well as the overall performance."
      ],
      "metadata": {
        "id": "CmRuhohTDtYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "# Get predictions for the validation data\n",
        "predictions = model.predict(X_val_tensor)\n",
        "\n",
        "# LSTM Evaluation (for demonstration, evaluating on training data)\n",
        "lstm_pred = model.predict(X_val_tensor).cpu().numpy()\n",
        "\n",
        "# Flatten both predictions and true labels to compare them element-wise\n",
        "lstm_pred_flat = lstm_pred.view(-1).cpu().numpy()  # Flatten the predicted labels and move to CPU\n",
        "y_val_flat = y_val_tensor.view(-1).cpu().numpy()   # Flatten the true labels and move to CPU\n",
        "\n",
        "# Generate the classification report\n",
        "target_names = ['Helix (H)', 'Sheet (E)', 'Coil (C)', 'Turn (T)', 'Bend (B)', 'Bridge (G)', 'Polyproline (P)', 'I-helix (I)', 'Other (-)']\n",
        "lstm_report = classification_report(y_val_flat, lstm_pred_flat, target_names=target_names)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"LSTM Classification Report:\\n\", lstm_report)"
      ],
      "metadata": {
        "id": "549Xfc7DDvjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Conclusion\n",
        "\n",
        "In this chapter, we built machine learning and deep learning models to predict protein secondary structure from amino acid sequences. We explored the use of traditional classifiers like Random Forests and advanced deep learning architectures like LSTMs. While traditional methods perform well for small datasets, deep learning models can capture long-range dependencies and improve performance when dealing with larger datasets."
      ],
      "metadata": {
        "id": "3v-NDlQGDybB"
      }
    }
  ]
}