{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gokceuludogan/protein-ml-crash-course/blob/wip/Chapter_5_Protein_Function_Prediction_with_Gene_Ontology_(GO).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CezLEGbeDh4z"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Protein function prediction is a crucial task in bioinformatics, where we aim to determine the biological role of a protein based on its sequence or structure. A popular framework for describing protein functions is the **Gene Ontology (GO)**. GO provides a structured vocabulary for annotating proteins, organized into three main categories:\n",
        "\n",
        "- **Biological Process (BP)**: Pathways and processes a protein is involved in (e.g., cell cycle).\n",
        "- **Molecular Function (MF)**: Specific activities performed by the protein (e.g., binding).\n",
        "- **Cellular Component (CC)**: Locations within the cell where the protein operates (e.g., nucleus).\n",
        "\n",
        "In this chapter, we will:\n",
        "\n",
        "- Introduce the Gene Ontology.\n",
        "- Explain how to prepare a dataset for GO-based function prediction.\n",
        "- Build machine learning models for predicting GO terms using sequence or structural features.\n",
        "- Evaluate the performance of these models.\n",
        "\n",
        "## 1. Introduction to Gene Ontology (GO)\n",
        "\n",
        "### What is Gene Ontology?\n",
        "\n",
        "The **Gene Ontology** is a hierarchical system that classifies protein functions using a controlled vocabulary. Each GO term describes a specific aspect of a protein's role in the cell, and these terms are organized in a directed acyclic graph (DAG). This allows for hierarchical relationships between general terms (e.g., \"metabolic process\") and specific ones (e.g., \"glycolysis\").\n",
        "\n",
        "### Key GO Categories:\n",
        "\n",
        "- **Biological Process (BP)**: Pathways and larger processes (e.g., \"DNA repair\").\n",
        "- **Molecular Function (MF)**: Specific biochemical activities (e.g., \"ATP binding\").\n",
        "- **Cellular Component (CC)**: Where in the cell the protein is located (e.g., \"mitochondrion\").\n",
        "\n",
        "Each protein can be annotated with multiple GO terms across these categories.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Preparing a Dataset for Protein Function Prediction\n",
        "\n",
        "### Example Dataset:\n",
        "\n",
        "We will assume we have a dataset where each protein sequence is associated with one or more GO terms. This dataset may include:\n",
        "\n",
        "- Protein sequences\n",
        "- Known GO annotations (from BP, MF, or CC)\n",
        "\n",
        "| Sequence | GO Terms |\n",
        "| --- | --- |\n",
        "| MAGWELV | GO:0004674, GO:0005524, ... |\n",
        "| GGQVNLL | GO:0000166, GO:0004674, ... |\n",
        "\n",
        "The task is to predict the correct GO terms for new protein sequences.\n",
        "\n",
        "### Retrieving and Annotating Data with GO Terms\n",
        "We'll first retrieve protein sequences from UniProt SwissProt and annotate them with GO terms using UniProt-GOA. We will filter annotations based on the provided evidence codes (EXP, IDA, IMP, IGI, IEP, TAS, IC)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2dt9K_RJBwd",
        "outputId": "19c57458-866d-41f5-e934-5a7ca9227696"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Entry                                           Sequence  \\\n",
            "0  A0A0C5B5G6                                   MRWQEMGYIFYPRKLR   \n",
            "1  A0A1B0GTW7  MLLLLLLLLLLPPLVLRVAASRCLHDETQKSVSLLRPPFSQLPSKS...   \n",
            "2      A0JNW5  MAGIIKKQILKHLSRFTKNLSPDKINLSTLKGEGELKNLELDEEVL...   \n",
            "5      A1A4S6  MGLQPLEFSDCYLDSPWFRERIRAHEAELERTNKFIKELIKDGKNL...   \n",
            "6      A1A519  MKRRQKRKHLENEESQETAEKGGGMSKSQEDALQPGSTRVAKGWSQ...   \n",
            "\n",
            "                                               BP_GO  \\\n",
            "0  GO:0032147,GO:2001145,GO:0001649,GO:0033687,GO...   \n",
            "1                   GO:0007155,GO:0061966,GO:0006508   \n",
            "2                              GO:0034498,GO:0120009   \n",
            "5        GO:0007010,GO:0043066,GO:0051056,GO:0007165   \n",
            "6                   GO:0009566,GO:0045893,GO:0006366   \n",
            "\n",
            "                              MF_GO  \\\n",
            "0             GO:0003677,GO:0140297   \n",
            "1  GO:0046872,GO:0004222,GO:0008233   \n",
            "2  GO:0062069,GO:0120013,GO:0042803   \n",
            "5                        GO:0005096   \n",
            "6             GO:0003677,GO:0046872   \n",
            "\n",
            "                                         CC_GO  \\\n",
            "0             GO:0005615,GO:0005739,GO:0005634   \n",
            "1                        GO:0005737,GO:0016020   \n",
            "2                        GO:0005829,GO:0005769   \n",
            "5  GO:0005829,GO:0010008,GO:0048471,GO:0005886   \n",
            "6                                   GO:0005634   \n",
            "\n",
            "                                              All_GO  \n",
            "0  GO:0032147,GO:2001145,GO:0001649,GO:0033687,GO...  \n",
            "1  GO:0007155,GO:0061966,GO:0006508,GO:0046872,GO...  \n",
            "2  GO:0034498,GO:0120009,GO:0062069,GO:0120013,GO...  \n",
            "5  GO:0007010,GO:0043066,GO:0051056,GO:0007165,GO...  \n",
            "6  GO:0009566,GO:0045893,GO:0006366,GO:0003677,GO...  \n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Example query to get SwissProt proteins\n",
        "query = \"reviewed:true AND organism_id:9606\"\n",
        "columns = \"accession,sequence,go_p,go_f,go_c\"\n",
        "base_url = \"https://rest.uniprot.org/uniprotkb/search\"\n",
        "\n",
        "# Parameters for the API call\n",
        "params = {\n",
        "    \"query\": query,\n",
        "    \"format\": \"tsv\",  # We want to retrieve tab-separated values\n",
        "    \"fields\": columns\n",
        "}\n",
        "\n",
        "# Make the request\n",
        "response = requests.get(base_url, params=params)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Convert to DataFrame\n",
        "    data = response.text\n",
        "    df = pd.DataFrame([x.split('\\t') for x in data.split('\\n')[1:] if x], columns=['Entry', 'Sequence', 'BP_GO', 'MF_GO', 'CC_GO'])\n",
        "\n",
        "    go_cols = ['BP_GO', 'MF_GO', 'CC_GO']\n",
        "\n",
        "    # Convert empty GO annotations to nan \n",
        "    df[go_cols] = df[go_cols].replace(\"\", np.nan)\n",
        "\n",
        "    # Drop rows without GO annotations\n",
        "    df = df.dropna(subset=go_cols)\n",
        "\n",
        "    # Format columns related to GO into a comma separated GO:XXXXXXX value list\n",
        "    for col in go_cols: df[col] = df[col].str.extractall(r'\\[(GO:\\d+)\\]').groupby(level=0).agg(','.join)\n",
        "\n",
        "    # Extract GO terms into one column and filter based on evidence codes\n",
        "    df['All_GO'] = df[['BP_GO', 'MF_GO', 'CC_GO']].apply(lambda x: ','.join(x.dropna()), axis=1)\n",
        "\n",
        "    print(df.head())  # Display first few rows of the dataframe\n",
        "else:\n",
        "    print(f\"Failed to retrieve data: {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting goatools\n",
            "  Downloading goatools-1.4.12-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting docopt (from goatools)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting ftpretty (from goatools)\n",
            "  Downloading ftpretty-0.4.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy in ./ccourse/lib/python3.9/site-packages (from goatools) (2.0.2)\n",
            "Collecting openpyxl (from goatools)\n",
            "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pandas in ./ccourse/lib/python3.9/site-packages (from goatools) (2.2.3)\n",
            "Collecting pydot (from goatools)\n",
            "  Downloading pydot-3.0.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests in ./ccourse/lib/python3.9/site-packages (from goatools) (2.32.3)\n",
            "Collecting rich (from goatools)\n",
            "  Downloading rich-13.9.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: scipy in ./ccourse/lib/python3.9/site-packages (from goatools) (1.13.1)\n",
            "Requirement already satisfied: setuptools in ./ccourse/lib/python3.9/site-packages (from goatools) (75.1.0)\n",
            "Collecting statsmodels (from goatools)\n",
            "  Downloading statsmodels-0.14.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
            "Collecting xlsxwriter (from goatools)\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: python-dateutil in ./ccourse/lib/python3.9/site-packages (from ftpretty->goatools) (2.9.0.post0)\n",
            "Collecting et-xmlfile (from openpyxl->goatools)\n",
            "  Downloading et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./ccourse/lib/python3.9/site-packages (from pandas->goatools) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./ccourse/lib/python3.9/site-packages (from pandas->goatools) (2024.2)\n",
            "Collecting pyparsing>=3.0.9 (from pydot->goatools)\n",
            "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./ccourse/lib/python3.9/site-packages (from requests->goatools) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./ccourse/lib/python3.9/site-packages (from requests->goatools) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./ccourse/lib/python3.9/site-packages (from requests->goatools) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./ccourse/lib/python3.9/site-packages (from requests->goatools) (2024.8.30)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->goatools)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./ccourse/lib/python3.9/site-packages (from rich->goatools) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in ./ccourse/lib/python3.9/site-packages (from rich->goatools) (4.12.2)\n",
            "Collecting patsy>=0.5.6 (from statsmodels->goatools)\n",
            "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in ./ccourse/lib/python3.9/site-packages (from statsmodels->goatools) (24.1)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->goatools)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: six in ./ccourse/lib/python3.9/site-packages (from patsy>=0.5.6->statsmodels->goatools) (1.16.0)\n",
            "Downloading goatools-1.4.12-py3-none-any.whl (15.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading ftpretty-0.4.0-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "Downloading pydot-3.0.2-py3-none-any.whl (35 kB)\n",
            "Downloading rich-13.9.2-py3-none-any.whl (242 kB)\n",
            "Downloading statsmodels-0.14.4-cp39-cp39-macosx_11_0_arm64.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
            "Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
            "Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=93e32d358c9ffff71c26c171d70e29e158aa3cb9790805e69aedc0ac5abdfe5b\n",
            "  Stored in directory: /Users/ozdeniz/Library/Caches/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
            "Successfully built docopt\n",
            "Installing collected packages: docopt, xlsxwriter, pyparsing, patsy, mdurl, et-xmlfile, pydot, openpyxl, markdown-it-py, ftpretty, statsmodels, rich, goatools\n",
            "Successfully installed docopt-0.6.2 et-xmlfile-1.1.0 ftpretty-0.4.0 goatools-1.4.12 markdown-it-py-3.0.0 mdurl-0.1.2 openpyxl-3.1.5 patsy-0.5.6 pydot-3.0.2 pyparsing-3.1.4 rich-13.9.2 statsmodels-0.14.4 xlsxwriter-3.2.0\n",
            "--2024-10-11 14:44:29--  http://current.geneontology.org/ontology/go-basic.obo\n",
            "Resolving current.geneontology.org (current.geneontology.org)... 3.160.57.85, 3.160.57.3, 3.160.57.18, ...\n",
            "Connecting to current.geneontology.org (current.geneontology.org)|3.160.57.85|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31220894 (30M) [text/obo]\n",
            "Saving to: ‘go-basic.obo’\n",
            "\n",
            "go-basic.obo        100%[===================>]  29,77M  3,80MB/s    in 7,7s    \n",
            "\n",
            "2024-10-11 14:44:37 (3,85 MB/s) - ‘go-basic.obo’ saved [31220894/31220894]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install goatools\n",
        "!wget http://current.geneontology.org/ontology/go-basic.obo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "M8N1tWn3MOkL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "go-basic.obo: fmt(1.2) rel(2024-09-08) 44,296 Terms\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'GOTerm' object has no attribute 'evidence'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[87], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filtered_terms\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Apply the filter to retain only high-confidence GO terms\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFiltered_GO\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAll_GO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgo_terms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_go_annotations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgo_terms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Remove proteins with no filtered GO terms\u001b[39;00m\n\u001b[1;32m     15\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFiltered_GO\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mlen\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m~/Desktop/crashcourse/protein-ml-crash-course/ccourse/lib/python3.9/site-packages/pandas/core/series.py:4917\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/crashcourse/protein-ml-crash-course/ccourse/lib/python3.9/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/crashcourse/protein-ml-crash-course/ccourse/lib/python3.9/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
            "File \u001b[0;32m~/Desktop/crashcourse/protein-ml-crash-course/ccourse/lib/python3.9/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/crashcourse/protein-ml-crash-course/ccourse/lib/python3.9/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
            "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "Cell \u001b[0;32mIn[87], line 12\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(go_terms)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filtered_terms\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Apply the filter to retain only high-confidence GO terms\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFiltered_GO\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll_GO\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m go_terms: \u001b[43mfilter_go_annotations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgo_terms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Remove proteins with no filtered GO terms\u001b[39;00m\n\u001b[1;32m     15\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFiltered_GO\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mlen\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
            "Cell \u001b[0;32mIn[87], line 8\u001b[0m, in \u001b[0;36mfilter_go_annotations\u001b[0;34m(go_terms)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter_go_annotations\u001b[39m(go_terms):\n\u001b[0;32m----> 8\u001b[0m     filtered_terms \u001b[38;5;241m=\u001b[39m [go_term \u001b[38;5;28;01mfor\u001b[39;00m go_term \u001b[38;5;129;01min\u001b[39;00m go_terms \u001b[38;5;28;01mif\u001b[39;00m go[go_term]\u001b[38;5;241m.\u001b[39mevidence \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEXP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIDA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIMP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIGI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIEP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTAS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIC\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filtered_terms\n",
            "Cell \u001b[0;32mIn[87], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter_go_annotations\u001b[39m(go_terms):\n\u001b[0;32m----> 8\u001b[0m     filtered_terms \u001b[38;5;241m=\u001b[39m [go_term \u001b[38;5;28;01mfor\u001b[39;00m go_term \u001b[38;5;129;01min\u001b[39;00m go_terms \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mgo\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgo_term\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevidence\u001b[49m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEXP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIDA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIMP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIGI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIEP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTAS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIC\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filtered_terms\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GOTerm' object has no attribute 'evidence'"
          ]
        }
      ],
      "source": [
        "from goatools import obo_parser\n",
        "\n",
        "# Load GO terms from an ontology file (e.g., GO.obo)\n",
        "go = obo_parser.GODag(\"go-basic.obo\")\n",
        "\n",
        "# Filter function for keeping GO terms with specific evidence codes\n",
        "def filter_go_annotations(go_terms):\n",
        "    filtered_terms = [go_term for go_term in go_terms if go[go_term].evidence in ['EXP', 'IDA', 'IMP', 'IGI', 'IEP', 'TAS', 'IC']]\n",
        "    return filtered_terms\n",
        "\n",
        "# Apply the filter to retain only high-confidence GO terms\n",
        "df['Filtered_GO'] = df['All_GO'].apply(lambda go_terms: filter_go_annotations(go_terms.split(',')))\n",
        "\n",
        "# Remove proteins with no filtered GO terms\n",
        "df = df[df['Filtered_GO'].map(len) > 0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdPcFRSfDfYL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('protein_go_dataset.csv')\n",
        "\n",
        "# Split into sequences and GO terms\n",
        "X = df['Sequence']\n",
        "y = df['GO Terms'].apply(lambda x: x.split(','))  # Split GO terms into lists\n",
        "\n",
        "# Encode GO terms using MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "y_encoded = mlb.fit_transform(y)\n",
        "\n",
        "# Display encoded GO terms\n",
        "print(\"GO Terms Shape:\", y_encoded.shape)\n",
        "print(\"Example of GO Terms for a Protein:\", y_encoded[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUGBwIkMD5OG"
      },
      "source": [
        "## 3. Traditional Machine Learning for GO Prediction\n",
        "\n",
        "For this task, we can use traditional ML models like **Logistic Regression**, **Random Forest**, or **SVM** in a multi-label classification setup. Since each protein may have multiple GO annotations, we will use **multi-label classification**, where the model predicts multiple classes (GO terms) for each protein."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EG1KCDa4D3y_"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# One-hot encode protein sequences (same as previous chapters)\n",
        "X_train_encoded = np.array([one_hot_encode(seq) for seq in X_train])\n",
        "X_test_encoded = np.array([one_hot_encode(seq) for seq in X_test])\n",
        "\n",
        "# Train Logistic Regression model for multi-label classification\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train_encoded, y_train)\n",
        "\n",
        "# Predict GO terms on the test set\n",
        "y_pred = logreg.predict(X_test_encoded)\n",
        "\n",
        "# Evaluate model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_QxR1RMD1E3"
      },
      "source": [
        "## 5. Model Evaluation\n",
        "\n",
        "Since this is a **multi-label classification** task, traditional accuracy isn't enough to fully evaluate the model's performance. We should use metrics like **precision**, **recall**, and **F1-score** for each GO term."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "locfp7bZDzg1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Predict on the test set (using logistic regression for demonstration)\n",
        "y_pred = logreg.predict(X_test_encoded)\n",
        "\n",
        "# Convert predictions to binary format\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Generate classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_binary, target_names=mlb.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl1Bex_ODw_S"
      },
      "source": [
        "## 6. Conclusion\n",
        "\n",
        "In this chapter, we introduced the **Gene Ontology (GO)** framework for protein function prediction and explored how to build machine learning and deep learning models to predict GO terms based on protein sequences. We demonstrated how to handle multi-label classification, using both traditional ML models and deep learning architectures."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO3ePhmNs6ola+mxWyBqGdQ",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ccourse",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
